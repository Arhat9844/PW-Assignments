{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Create a Folder and Initialize a Git Repository\n",
    "Open a terminal and create a new project folder:\n",
    "code\n",
    "mkdir ml_project\n",
    "cd ml_project\n",
    "git init\n",
    "\n",
    "Step 2: Create a Virtual Environment\n",
    "Create and activate a virtual environment:\n",
    "code-\n",
    "# Create a virtual environment\n",
    "python -m venv venv\n",
    "\n",
    "# Activate the virtual environment (Windows)\n",
    "venv\\Scripts\\activate\n",
    "\n",
    "# Activate the virtual environment (macOS/Linux)\n",
    "source venv/bin/activate\n",
    "\n",
    "Step 3: Create Folder Structure\n",
    "Create the folder structure:\n",
    "mkdir -p src/components src/pipeline\n",
    "touch src/__init__.py src/logger.py src/exception.py src/utils.py\n",
    "touch src/components/__init__.py src/components/data_ingestion.py src/components/data_transformation.py src/components/model_trainer.py\n",
    "touch src/pipeline/__init__.py src/pipeline/predict_pipeline.py src/pipeline/train_pipeline.py\n",
    "touch import_data.py setup.py requirements.txt\n",
    "mkdir notebooks\n",
    "\n",
    "Step 4: Initialize Git and Add Basic Files\n",
    "Create .gitignore, README.md, and LICENSE files:\n",
    "\n",
    "touch .gitignore README.md LICENSE\n",
    "\n",
    "Add common Python ignores to .gitignore:\n",
    "\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    ".vscode/\n",
    ".venv/\n",
    "venv/\n",
    "env/\n",
    ".DS_Store\n",
    "\n",
    "Add files and commit to git:\n",
    "\n",
    "git add .\n",
    "git commit -m \"Initial project setup\"\n",
    "\n",
    "Step 5: Setup setup.py and requirements.txt\n",
    "Open setup.py and add:\n",
    "from setuptools import find_packages, setup\n",
    "\n",
    "setup(\n",
    "    name='ml_project',\n",
    "    version='0.1',\n",
    "    author='Your Name',\n",
    "    author_email='your.email@example.com',\n",
    "    packages=find_packages(),\n",
    "    install_requires=[\n",
    "        'pandas',\n",
    "        'scikit-learn',\n",
    "        'numpy',\n",
    "        'Flask',\n",
    "    ],\n",
    ")\n",
    "\n",
    "Open requirements.txt and add:\n",
    "\n",
    "pandas\n",
    "scikit-learn\n",
    "numpy\n",
    "Flask\n",
    "\n",
    "Install the dependencies:\n",
    "pip install -r requirements.txt\n",
    "\n",
    "Step 6: Write Logging and Exception Modules\n",
    "Open src/logger.py and add:\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "LOG_DIR = \"logs\"\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "LOG_FILE = os.path.join(LOG_DIR, f\"log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "Open src/exception.py and add:\n",
    "\n",
    "class CustomException(Exception):\n",
    "    def __init__(self, message, error):\n",
    "        super().__init__(message)\n",
    "        self.error = error\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Error: {self.error}, Message: {self.message}\"\n",
    "\n",
    "Step 7: Create Jupyter Notebook\n",
    "In the notebooks directory, create a new Jupyter notebook called eda_and_model_training.ipynb.\n",
    "Step 8: Write the Import Data Script\n",
    "Open import_data.py and add:\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "def load_data():\n",
    "    data = load_breast_cancer()\n",
    "    df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "    df['target'] = data.target\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = load_data()\n",
    "    print(df.head())\n",
    "\n",
    "Step 9: Write the Data Ingestion Script\n",
    "Open src/components/data_ingestion.py and add:\n",
    "from import_data import load_data\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "\n",
    "    def ingest_data(self):\n",
    "        self.data = load_data()\n",
    "        return self.data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    di = DataIngestion()\n",
    "    data = di.ingest_data()\n",
    "    print(data.head())\n",
    "\n",
    "Step 10: Data Transformation\n",
    "Open src/components/data_transformation.py and add:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def transform_data(self):\n",
    "        features = self.data.drop('target', axis=1)\n",
    "        target = self.data['target']\n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "        return features_scaled, target\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from data_ingestion import DataIngestion\n",
    "    di = DataIngestion()\n",
    "    data = di.ingest_data()\n",
    "    dt = DataTransformation(data)\n",
    "    features, target = dt.transform_data()\n",
    "    print(features[:5], target[:5])\n",
    "\n",
    "Step 11: Model Trainer\n",
    "Open src/components/model_trainer.py and add:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, features, target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def train_model(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.features, self.target, test_size=0.2, random_state=42)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        return model, accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from data_ingestion import DataIngestion\n",
    "    from data_transformation import DataTransformation\n",
    "\n",
    "    di = DataIngestion()\n",
    "    data = di.ingest_data()\n",
    "    dt = DataTransformation(data)\n",
    "    features, target = dt.transform_data()\n",
    "\n",
    "    mt = ModelTrainer(features, target)\n",
    "    model, accuracy = mt.train_model()\n",
    "    print(f\"Model Accuracy: {accuracy}\")\n",
    "\n",
    "Step 12: Flask Application\n",
    "Create app.py and add:\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from src.components.data_ingestion import DataIngestion\n",
    "from src.components.data_transformation import DataTransformation\n",
    "from src.components.model_trainer import ModelTrainer\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/train', methods=['GET'])\n",
    "def train():\n",
    "    di = DataIngestion()\n",
    "    data = di.ingest_data()\n",
    "    dt = DataTransformation(data)\n",
    "    features, target = dt.transform_data()\n",
    "    mt = ModelTrainer(features, target)\n",
    "    model, accuracy = mt.train_model()\n",
    "    return jsonify({\"accuracy\": accuracy})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "Step 13: Update Git Repository\n",
    "Add and commit the changes to the Git repository:\n",
    "\n",
    "git add .\n",
    "git commit -m \"Added ML project structure and initial code\"\n",
    "git push origin main\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
