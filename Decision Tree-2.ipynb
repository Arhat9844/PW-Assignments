{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1--\n",
    "# Answer--\n",
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "diabetes_data = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(diabetes_data.head())\n",
    "\n",
    "# Display descriptive statistics\n",
    "print(diabetes_data.describe())\n",
    "\n",
    "# Plot histograms for each variable\n",
    "diabetes_data.hist(figsize=(12, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(diabetes_data.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2--\n",
    "# Answer----\n",
    "# Check for missing values\n",
    "print(diabetes_data.isnull().sum())\n",
    "\n",
    "# Remove outliers using IQR method\n",
    "Q1 = diabetes_data.quantile(0.25)\n",
    "Q3 = diabetes_data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "diabetes_data_cleaned = diabetes_data[~((diabetes_data < (Q1 - 1.5 * IQR)) | (diabetes_data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# Encode categorical variables into dummy variables if necessary\n",
    "# No categorical variables are present in this dataset\n",
    "\n",
    "# Display the shape of the cleaned dataset\n",
    "print(\"Shape of cleaned dataset:\", diabetes_data_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3--\n",
    "# Answer--from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = diabetes_data_cleaned.drop('Outcome', axis=1)\n",
    "y = diabetes_data_cleaned['Outcome']\n",
    "\n",
    "# Split the dataset into training and test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the shapes of the train and test sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4--\n",
    "# Answer--\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(dt_classifier, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the decision tree model with the best hyperparameters\n",
    "best_dt_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "best_dt_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5--\n",
    "# Answer--from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_dt_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "y_proba = best_dt_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='grey')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6--\n",
    "# Answer--\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(best_dt_model, feature_names=X.columns, class_names=['Non-diabetic', 'Diabetic'], filled=True, fontsize=10)\n",
    "plt.show()\n",
    "##This code plots the decision tree, displaying the splits, branches, and leaves. Each node in the tree represents a decision based on a feature and threshold. The most important variables are those that appear higher up in the tree and are used for early splits, as they have the most significant impact on the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7--\n",
    "# Answer--\n",
    "Apply the Model to New Data:\n",
    "\n",
    "Load the new dataset with similar clinical variables into VS Code.\n",
    "Use the trained decision tree model to predict outcomes for the new data.\n",
    "Evaluate the model's performance metrics, such as accuracy, precision, recall, and F1 score, using Python code within VS Code.\n",
    "Sensitivity Analysis:\n",
    "\n",
    "Write Python code in VS Code to vary one or more input variables within a plausible range.\n",
    "Use the trained decision tree model to predict outcomes for the varied input variables.\n",
    "Analyze the changes in predictions and assess the model's sensitivity to input variable changes.\n",
    "Scenario Testing:\n",
    "\n",
    "Define different scenarios representing potential changes in the dataset or environment.\n",
    "Implement Python code in VS Code to apply the decision tree model to each scenario.\n",
    "Evaluate the model's predictions under different conditions and assess its consistency and reliability across scenarios.\n",
    "Cross-Validation:\n",
    "\n",
    "Utilize Python libraries like scikit-learn within VS Code to perform cross-validation on multiple subsets of the original dataset.\n",
    "Assess the stability and generalization ability of the model by evaluating performance metrics across different folds of the data.\n",
    "Out-of-Sample Testing:\n",
    "\n",
    "Load additional datasets or test sets into VS Code.\n",
    "Apply the trained decision tree model to these unseen datasets.\n",
    "Evaluate the model's performance on the new data and assess its ability to generalize to unseen datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "2021.11.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
