{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1=\n",
    "ANSWER==\n",
    "sklearn.datasets.\n",
    "ChatGPT\n",
    "Sure! Here's a step-by-step Python code to implement the K-Nearest Neighbors (KNN) classifier algorithm on the Iris dataset using the sklearn.datasets module.\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)  # You can choose the number of neighbors\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of KNN classifier: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2=\n",
    "ANSWER==\n",
    "The following Python code demonstrates how to implement the K-Nearest Neighbors (KNN) regressor algorithm on the Boston housing dataset using sklearn.datasets. Note that the load_boston dataset has been deprecated in scikit-learn 1.0, so we'll use the fetch_california_housing dataset instead, which is a suitable alternative for regression tasks.\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the KNN regressor\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)  # You can choose the number of neighbors\n",
    "\n",
    "# Train the regressor\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the regressor using Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error of KNN regressor: {mse:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3=\n",
    "ANSWER==\n",
    "Here is a Python code snippet that uses cross-validation to find the optimal value of \n",
    "ùëò\n",
    "k for the K-Nearest Neighbors (KNN) classifier on the Iris dataset. We will use GridSearchCV from sklearn.model_selection to perform an exhaustive search over specified parameter values.\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter grid for the number of neighbors\n",
    "param_grid = {'n_neighbors': np.arange(1, 31)}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the optimal number of neighbors\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "print(f\"The optimal number of neighbors is {best_k}\")\n",
    "\n",
    "# Train the KNN classifier with the optimal number of neighbors\n",
    "knn_optimal = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_optimal.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = knn_optimal.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of KNN classifier with {best_k} neighbors: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4=\n",
    "ANSWER==\n",
    "The load_boston dataset has been deprecated in scikit-learn 1.2.0, so it's recommended to use the fetch_california_housing dataset instead. However, for illustration purposes, I'll show how to use the load_boston dataset with feature scaling using StandardScaler.\n",
    "\n",
    "Here is the code to implement the KNN regressor algorithm with feature scaling on the Boston housing dataset using StandardScaler:\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the KNN regressor\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)  # You can choose the number of neighbors\n",
    "\n",
    "# Train the regressor\n",
    "knn_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = knn_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the regressor using Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error of KNN regressor: {mse:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5=\n",
    "ANSWER==\n",
    "Here's a Python code snippet to implement the KNN classifier algorithm with weighted voting on the load_iris dataset using sklearn.datasets:\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the KNN classifier with weighted voting\n",
    "knn_weighted = KNeighborsClassifier(weights='distance')  # Using 'distance' for weighted voting\n",
    "\n",
    "# Train the classifier\n",
    "knn_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred_weighted = knn_weighted.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier with weighted voting\n",
    "accuracy_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "\n",
    "print(f\"Accuracy of KNN classifier with weighted voting: {accuracy_weighted * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6=\n",
    "ANSWER==\n",
    "To standardize the features before applying the KNN classifier, you can use the StandardScaler from sklearn.preprocessing. Here's a Python function that standardizes the features of a dataset:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize_features(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardize the features of training and testing sets.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train : array-like\n",
    "        Training data.\n",
    "    X_test : array-like\n",
    "        Testing data.\n",
    "    \n",
    "    Returns:\n",
    "    X_train_scaled : array-like\n",
    "        Standardized training data.\n",
    "    X_test_scaled : array-like\n",
    "        Standardized testing data.\n",
    "    \"\"\"\n",
    "    # Initialize StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit scaler to training data and transform training data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Transform testing data using the same scaler fitted on training data\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "You can use this function to standardize the features of your training and testing datasets before applying the KNN classifier. Here's how you can use it:\n",
    "# Assuming X_train and X_test are your training and testing feature matrices\n",
    "X_train_scaled, X_test_scaled = standardize_features(X_train, X_test)\n",
    "\n",
    "# Create and train KNN classifier on standardized data\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of KNN classifier with standardized features: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7=\n",
    "ANSWER==\n",
    "here's a Python function to calculate the Euclidean distance between two points:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points.\n",
    "    \n",
    "    Parameters:\n",
    "    point1 : array-like\n",
    "        Coordinates of the first point.\n",
    "    point2 : array-like\n",
    "        Coordinates of the second point.\n",
    "    \n",
    "    Returns:\n",
    "    distance : float\n",
    "        Euclidean distance between the two points.\n",
    "    \"\"\"\n",
    "    # Convert points to numpy arrays to handle both lists and arrays\n",
    "    point1 = np.array(point1)\n",
    "    point2 = np.array(point2)\n",
    "    \n",
    "    # Calculate Euclidean distance\n",
    "    distance = np.linalg.norm(point1 - point2)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "# Example usage\n",
    "point1 = [1, 2, 3]\n",
    "point2 = [4, 5, 6]\n",
    "\n",
    "distance = euclidean_distance(point1, point2)\n",
    "print(\"Euclidean distance between point1 and point2:\", distance)\n",
    "\n",
    "Euclidean distance between point1 and point2: 5.196152422706632\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8=\n",
    "ANSWER==Here's a Python function to calculate the Manhattan distance between two points:\n",
    "import numpy as np\n",
    "\n",
    "def manhattan_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Manhattan distance between two points.\n",
    "    \n",
    "    Parameters:\n",
    "    point1 : array-like\n",
    "        Coordinates of the first point.\n",
    "    point2 : array-like\n",
    "        Coordinates of the second point.\n",
    "    \n",
    "    Returns:\n",
    "    distance : float\n",
    "        Manhattan distance between the two points.\n",
    "    \"\"\"\n",
    "    # Convert points to numpy arrays to handle both lists and arrays\n",
    "    point1 = np.array(point1)\n",
    "    point2 = np.array(point2)\n",
    "    \n",
    "    # Calculate Manhattan distance\n",
    "    distance = np.sum(np.abs(point1 - point2))\n",
    "    \n",
    "    return distance\n",
    "\n",
    "\n",
    "# Example usage\n",
    "point1 = [1, 2, 3]\n",
    "point2 = [4, 5, 6]\n",
    "\n",
    "distance = manhattan_distance(point1, point2)\n",
    "print(\"Manhattan distance between point1 and point2:\", distance)\n",
    "\n",
    "Manhattan distance between point1 and point2: 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
